{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67bad2f-25b2-4c5c-8b51-df13c7bd7d27",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "1) Chatbot with profile schema\n",
    "2) For Complex Schema use `TrustCall` - Intro and an example\n",
    "3) Chatbot with profile schema updating \\w trustcall\n",
    "4) Chatbot with Collection Schema instead of profile - For more flexibility using `Pydantic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73cfa21-0b43-461a-b086-ef5dee0a91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from IPython.display import display, Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, RemoveMessage, AnyMessage, merge_message_runs\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44450011-33c9-4552-96ed-324a8831e08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ff63ac-f00c-44af-892f-def83e956f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"/gpfs/projects/bsc02/llm_models/huggingface_models/Qwen3-32B\",\n",
    "    openai_api_key=\"dummy\",  # vLLM doesn't need a real key\n",
    "    openai_api_base=\"http://localhost:8002/v1\",  # Your forwarded port\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0e3aec-f155-4641-80a4-63082859246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserProfile(TypedDict):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "    user_name: str        # The user's preferred name\n",
    "    interests: list[str]  # A list of the user's interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "044da407-710a-4617-b0c1-893030b39290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TypedDict instance\n",
    "user_profile: UserProfile = {\n",
    "    \"user_name\": \"Lance\",\n",
    "    \"interests\": [\"biking\", \"technology\", \"coffee\"]\n",
    "}\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90384571-5770-4b07-9011-8393910cdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memory\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = \"user_profile\"\n",
    "value = user_profile\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d472abbd-5c3a-4c06-b2e5-997b92750d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}, 'created_at': '2026-02-24T10:54:30.253843+00:00', 'updated_at': '2026-02-24T10:54:30.253848+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search \n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d12de05-ddee-46b8-89fb-63d04e2357bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the memory by namespace and key\n",
    "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
    "profile.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690a884-51be-4f85-9f2a-16350749e8eb",
   "metadata": {},
   "source": [
    "## Chatbot with profile schema\n",
    "- Basically LLM `StructuredOutput`\n",
    "- modeling a distributed, namespaced memory hierarchy under the hood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a01f6d76-5850-49c4-968b-514d0eaff693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(UserProfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38a2bda2-0033-48cc-966b-db3c9418963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the model to produce structured output that matches the schema\n",
    "structured_output = model_with_structure.invoke([HumanMessage(\"My name is Lance, I like to bike.\")])\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca26410a-a6f0-4e5b-ab23-d47645a718f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad9a48c0-d67e-4148-b778-66706a377eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history. \n",
    "This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "Here is the existing memory (it may be empty): {memory}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1620f-93a7-4e9b-9950-af090194b965",
   "metadata": {},
   "source": [
    "The function `call_model` is designed to:\n",
    "\n",
    "- `Load the user’s stored memory, use it to personalize the system prompt, and then generate a response from the model that blends both past memory and current messages.`\n",
    "\n",
    "- It’s a micro-agent callback that bridges:\n",
    "  - The `store layer` (long-term or cross-session memory),\n",
    "  - The `state layer` (current chat context),\n",
    "  - The `model invocation layer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe968a1-f871-4a93-a390-49625d2fb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"] # scope key for personalized memory.\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    '''\n",
    "        {\n",
    "      (\"memory\", \"user_123\"): {\n",
    "          \"user_memory\": {\n",
    "              \"user_name\": \"John\",\n",
    "              \"interests\": [\"AI\", \"Robotics\", \"LangGraph\"]\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "    '''\n",
    "    namespace = (\"memory\", user_id) ## It means find inside memory/user_id/user_memory\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "        \n",
    "    # Format the existing memory in the instruction\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "\n",
    "    # Invoke the model to produce structured output that matches the schema\n",
    "    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "\n",
    "    # Overwrite the existing use profile memory\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, new_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca4d0a38-ce9f-4da5-92c1-314d83cb98cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356ee721-1dff-4f08-aeb9-b8cead231fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance and I like to bike around San Francisco and eat at bakeries. Where can I find an amazing croissant?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is Lance again, and he's asking where to find an amazing croissant in San Francisco. He already mentioned his interests in biking and bakeries, so I should focus on bakeries that are known for their croissants and maybe even mention if they're near biking routes.\n",
      "\n",
      "First, I remember that in the previous conversation, I suggested Tartine. They are well-known for pastries, so that's a good start. But maybe there are other places too. Let me think of other top bakeries in SF. La Boulange is another popular one, they have great croissants and are located in several places, including the Ferry Building. That's a good spot because the Ferry Building is a nice area to bike around. \n",
      "\n",
      "Also, maybe recommend a place that's a bit more local or has a unique twist. How about Crepes & Croissants? They have a great reputation for their flaky croissants. Another option could be Acme Bread Company. They have a few locations, and their croissants are a favorite among locals. \n",
      "\n",
      "I should also consider if these bakeries are near bike-friendly areas. For example, La Boulange at the Ferry Building is on the Embarcadero, which is a great bike path. That way, Lance can bike along the waterfront and stop by. Tartine in the Mission District is another area with nice bike routes. \n",
      "\n",
      "I should also mention a couple of other spots just in case. Maybe Cinnaholic for a twist, though it's more cinnamon rolls, but they might have croissants too. Or maybe a French place like Pierre's Baguette in the Mission, which has a great reputation. \n",
      "\n",
      "I should check if there are any seasonal or special croissants. For example, during certain times of the year, some bakeries might have special flavors. Also, maybe mention the best time to go, like early morning for fresh croissants. \n",
      "\n",
      "Wait, the user is asking for an \"amazing\" croissant, so I should prioritize the most highly recommended ones. Tartine, La Boulange, Crepes & Croissants, Acme. Maybe rank them in order of popularity or quality. \n",
      "\n",
      "Also, include addresses or locations so Lance knows where to go. But since he's biking, maybe note the neighborhoods. For example, Tartine is in the Mission, La Boulange is in the Ferry Building\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance and I like to bike around San Francisco and eat at bakeries. Where can I find an amazing croissant?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb2437f-36ac-4950-86e6-c3cf18f9a923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance',\n",
       " 'interests': ['biking', 'San Francisco', 'bakeries', 'croissants']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0df2c-eef6-4d60-a7fa-360a452abfee",
   "metadata": {},
   "source": [
    "## For Complex Schema use `TrustCall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "771851c1-1b73-4dfb-b02c-285ca26a0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc54b7bf-e855-4354-bf87-5fc2b582a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Lance.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Lance.\"), \n",
    "                HumanMessage(content=\"I really like biking around San Francisco.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd39dfa9-b480-41c9-8d66-dcd15956e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema \n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    interests: list[str] = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "# Initialize the model\n",
    "model = model\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    llm=model,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\"\n",
    ")\n",
    "\n",
    "# Instruction\n",
    "system_msg = \"Extract the user profile from the following conversation\"\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8672fa81-e328-44c9-b0a7-21d22d35d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (chatcmpl-tool-bfb9a2a320314dc8)\n",
      " Call ID: chatcmpl-tool-bfb9a2a320314dc8\n",
      "  Args:\n",
      "    user_name: Lance\n",
      "    interests: ['biking around San Francisco']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0209854e-c6f2-4828-9ece-e88c11e2e739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(user_name='Lance', interests=['biking around San Francisco'])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = result[\"responses\"]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c84616cb-f548-49b4-85ef-3fee3788874c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking around San Francisco']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[0].model_dump() # serialize a Pydantic model instance into a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "024019ba-e37a-457b-b284-fe8e0eeaa068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [HumanMessage(content=\"Hi, I'm Lance.\"), \n",
    "                        AIMessage(content=\"Nice to meet you, Lance.\"), \n",
    "                        HumanMessage(content=\"I really like biking around San Francisco.\"),\n",
    "                        AIMessage(content=\"San Francisco is a great city! Where do you go after biking?\"),\n",
    "                        HumanMessage(content=\"I really like to go to a bakery after biking.\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\"\n",
    "\n",
    "# Invoke the extractor with the updated instruction and existing profile with the corresponding tool name (UserProfile)\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+updated_conversation}, \n",
    "                                    {\"existing\": {\"UserProfile\": schema[0].model_dump()}})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ae5acb3-364a-4512-93ec-4a219bcfb990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (chatcmpl-tool-96a73f97f3e6c334)\n",
      " Call ID: chatcmpl-tool-96a73f97f3e6c334\n",
      "  Args:\n",
      "    user_name: Lance\n",
      "    interests: ['biking', 'bakery']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82799f13-9164-42aa-98c4-31c47681973b",
   "metadata": {},
   "source": [
    "## Chatbot with `profile` schema updating \\w trustcall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45fc5813-bceb-47e2-a702-1774e53449ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema \n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\" Profile of a user \"\"\"\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    user_location: str = Field(description=\"The user's location\")\n",
    "    interests: list = Field(description=\"A list of the user's interests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73996288-393f-4b61-a03e-ed879a75f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\", # Enforces use of the UserProfile tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df56bb42-35cc-43fb-8c0a-ef1273fad4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot system instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e8c8d8b-4b6e-4619-8326-5387455dd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Create or update the memory (JSON doc) to incorporate information from the following conversation:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca8ec91c-cae9-4770-bfc2-98e49d0f4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"      \n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "        \n",
    "    # Get the profile as the value from the list, and convert it to a JSON doc\n",
    "    existing_profile = {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
    "    \n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]+state[\"messages\"], \"existing\": existing_profile})\n",
    "    \n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = result[\"responses\"][0].model_dump()\n",
    "\n",
    "    # Save the updated profile\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, updated_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c28be55c-54f4-4311-b58f-cec258b19270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07581d01-ea83-4ede-bcec-38656633789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user introduced himself as Lance. Since there's no existing memory for him, I need to start fresh. I should acknowledge his name and offer assistance. Let me make sure to keep the response friendly and open-ended to encourage him to ask questions or share more. Maybe add an emoji to keep it approachable. Also, I should check if there's anything specific he needs help with today. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "Hi Lance! 👋 It's nice to meet you. How can I assist you today? Whether you have questions, need help with something specific, or just want to chat, I'm here for you! 😊\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e224944-9a42-4a12-a929-6bd77f3e3351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user mentioned they like to bike around San Francisco. Let me recall the previous conversation. The user's name is Lance, and now he's added that he enjoys biking in SF. I should update his profile with this information.\n",
      "\n",
      "First, I need to acknowledge his interest in biking. Then, maybe provide some useful information or recommendations related to biking in San Francisco. Let me think about the best bike routes there. The Golden Gate Park is a popular spot, so that's a good suggestion. Also, the Presidio and the Marin Headlands might be worth mentioning for scenic routes. \n",
      "\n",
      "I should also consider safety tips since biking in a city can have its challenges. Maybe mention helmet laws and bike lanes. Additionally, bike rental options could be helpful if he's a visitor. Oh, and the Bay Bridge is another iconic route, but it's steeper. \n",
      "\n",
      "I need to make sure the response is friendly and encouraging. Also, check if he needs more specific recommendations or has any particular questions. Let me structure the response with some key points and offer further assistance. \n",
      "\n",
      "Wait, the user might be a local or a tourist. I should keep it general but offer to provide more details if needed. Also, confirm if he's interested in trails, routes, or events. Alright, putting it all together now.\n",
      "</think>\n",
      "\n",
      "That’s awesome, Lance! 🚴 San Francisco is a fantastic city for biking, with plenty of scenic routes and bike-friendly areas. Here are a few spots you might enjoy:  \n",
      "\n",
      "- **Golden Gate Park**: A classic route with trails, greenery, and the iconic Golden Gate Bridge views.  \n",
      "- **Presidio**: A more rugged, historic area with trails and stunning ocean vistas.  \n",
      "- **Marin Headlands** (just across the bridge): Great for a longer ride with epic coastal views.  \n",
      "- **Bay Bridge** (if you’re up for a climb!): The eastern span has a dedicated bike path with amazing skyline views.  \n",
      "\n",
      "**Pro tip**: Always check the [SFMTA bike map](https://www.sfgo.com/bike) for safe routes and bike lane info. Also, consider a bike light and helmet—SF’s hills can be tricky!  \n",
      "\n",
      "Want recommendations for bike shops, rentals, or events in the area? Let me know! 😊\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1342d85-e2a8-4c45-9776-27e843e4bbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Lance',\n",
       "  'user_location': 'San Francisco',\n",
       "  'interests': ['biking']},\n",
       " 'created_at': '2026-02-24T12:32:02.342093+00:00',\n",
       " 'updated_at': '2026-02-24T12:32:02.342096+00:00'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8a3af19-5302-4396-8616-62cda16db8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, let's see. The user mentioned they enjoy going to bakeries. I need to connect this with their previous interest in biking around San Francisco. Maybe they want to know bakeries that are accessible by bike.\n",
      "\n",
      "First, I should list some popular bakeries in SF. Known names like Tartine, Bi-Rite, and maybe some local favorites. I should mention their locations to see if they're bike-friendly. Also, check if any have bike racks nearby.\n",
      "\n",
      "I should highlight a few spots that are good for post-ride stops. Maybe include some details like what they're known for—like pastries, bread, or coffee. Also, check if any have outdoor seating for a quick rest after biking.\n",
      "\n",
      "Need to make sure the information is up-to-date. Maybe mention if some bakeries have bike parking or if they're near bike routes. Also, maybe suggest combining a bike ride with a bakery stop, like a route that includes both.\n",
      "\n",
      "Pro tip could be about using a bike map app to find the best route to these bakeries. Maybe mention SF Go or Google Maps for bike directions.\n",
      "\n",
      "Also, ask if they need more recommendations or specific types of bakeries, like vegan or gluten-free options. Keep the tone friendly and helpful.\n",
      "</think>\n",
      "\n",
      "That’s a great combo—biking and bakery stops! San Francisco has some amazing bakeries that are perfect for a post-ride treat. Here are a few favorites that align with your interests:  \n",
      "\n",
      "### 🥐 **Bakeries Worth a Bike Detour**  \n",
      "1. **Tartine Bakery (Mission District)**  \n",
      "   - Known for: Warm, flaky pastries (try the bittersweet chocolate tart!) and sourdough bread.  \n",
      "   - Pro tip: They have a small outdoor area to sip coffee and rest your legs after a ride.  \n",
      "\n",
      "2. **Bi-Rite Creamery & Bakeshop (Mission District)**  \n",
      "   - Famous for: Seasonal pastries and incredible gelato. Their \"Bakeshop\" has a cozy vibe and bike racks nearby.  \n",
      "\n",
      "3. **Maison du Pain (Russian Hill)**  \n",
      "   - A French-style bakery with rustic bread, croissants, and European cakes. The scenic Russian Hill neighborhood is a fun ride through narrow streets.  \n",
      "\n",
      "4. **Café Luau (Haight-Ashbury)**  \n",
      "   - A local gem with a retro vibe and inventive pastries (like the \"C\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e136174f-3bcc-4406-bbd7-5099db453b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is Lance, based in San Francisco, and he's interested in biking and bakeries. He asked for bakery recommendations. Let me start by recalling some popular or highly-rated bakeries in SF that I know of.\n",
      "\n",
      "First, I should consider different neighborhoods since San Francisco is quite spread out. The Mission District is known for great food, so maybe Tartine Manufactory? That's a well-known spot for sourdough and pastries. Then there's the Ferry Building, which has the Boudin Bakery, famous for sourdough. The Fillmore area has Bi-Rite Creamery, which also does baked goods. Maybe include some in the Haight-Ashbury area, like La Boulange, which has a few locations. Oh, and in the Financial District, there's The Mill, which is a coffee and pastry place. \n",
      "\n",
      "I should also mention a few other neighborhoods. Chinatown has some good options too, like Mei Mei Asian Bakery for dim sum. For a more modern twist, maybe a place like Butter & Scotch in the Mission for their brioche buns. I should check if these places are still open and their current hours, but since I can't verify that in real-time, I'll present them as recommendations with a note to check for the latest info.\n",
      "\n",
      "Also, since Lance likes biking, maybe suggest some locations that are bike-friendly or have outdoor seating where he can relax after a ride. Mentioning the proximity to parks or bike paths might be helpful. For example, Tartine in the Mission is near Bernal Heights Park, so he could bike there after a hike. Bi-Rite in the Fillmore is near Golden Gate Park, which is a popular biking spot. \n",
      "\n",
      "I should structure the response by listing each bakery with a brief description, location, and maybe a highlight of their specialties. End with a friendly note to check for the latest updates and offer to help with more info if needed. Keep the tone friendly and helpful, using the user's name to personalize it.\n",
      "</think>\n",
      "\n",
      "Hey Lance! Since you're in San Francisco and love bakeries, here are some top spots I’d recommend for you to try, with a few bike-friendly tips too:\n",
      "\n",
      "### **Must-Try Bakeries in SF:**\n",
      "1. **Tartine Manufactory (Mission District)**  \n",
      "   - **Why go?** Iconic sourdough, pastries, and seasonal desserts. Try their\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750883c-0ebb-4da3-aa33-7d233d9d928b",
   "metadata": {},
   "source": [
    "## Chatbot with `Collection` Schema instead of profile\n",
    "\n",
    "- Instead of storing user information in a fixed profile structure, we'll create a flexible collection schema to store memories about user interactions.\n",
    "\n",
    "- Each memory will be stored as a separate entry with a single content field for the main information we want to remember\n",
    "\n",
    "- This approach allows us to build an open-ended collection of memories that can grow and change as we learn more about the user.\n",
    "\n",
    "- We can define a collection schema as a Pydantic object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f5a8b-26da-4792-a9fa-b170f4ee9336",
   "metadata": {},
   "source": [
    "### Advantage\n",
    "\n",
    "- ✅ 1. Open-ended and dynamic\n",
    "\n",
    "`You can add new types of memories without changing the structure.\n",
    "Each new interaction becomes a new entry; the system can grow naturally.`\n",
    "\n",
    "- ✅ 2. Easier retrieval and reasoning\n",
    "\n",
    "`You can query the collection for specific types of memory:\n",
    "memories_about_ai = [m for m in memory_collection if \"AI\" in m.content]`\n",
    "\n",
    "\n",
    "Works naturally for vector-based retrieval or similarity search.\n",
    "\n",
    "- ✅ 3. Better for multi-turn personalization\n",
    "\n",
    "`Each memory entry can represent one fact, one interaction, or one observation.\n",
    "Makes it easy to update, delete, or summarize without overwriting unrelated information.`\n",
    "\n",
    "- ✅ 4. Time-awareness\n",
    "\n",
    "`Each memory can have a timestamp (created_at), so you can track how user preferences evolve.\n",
    "Enables recency-based retrieval — e.g., only consider memories from the last week.`\n",
    "\n",
    "- ✅ 5. Schema enforcement with Pydantic\n",
    "\n",
    "Using Pydantic ensures type safety and validation:\n",
    "- `content is always a string`\n",
    "- `timestamp is always datetime`\n",
    "- `optional fields like category enforce consistent structure`\n",
    "\n",
    "At the same time, you don’t hardcode all fields like a traditional fixed profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eaf0985-9b4e-4a21-b9d7-fdd1a9b4e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c3f5beb-5757-40e5-8a2c-b1e4e44ae57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content='My name is Lance. I like to bike.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(MemoryCollection)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is Lance. I like to bike.\")])\n",
    "memory_collection.memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f719153-f7b7-43b9-9f3e-89375732b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'My name is Lance. I like to bike.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[0].model_dump()\n",
    "#memory_collection.memories[1].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99f25a89-5758-4de7-9f75-4f50112bb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f67dc0e-90f3-46a1-a4a5-edf249407206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memories'], 'key': 'a148c836-5435-4b43-9f35-ae9ea9dce05b', 'value': {'content': 'My name is Lance. I like to bike.'}, 'created_at': '2026-02-24T12:40:20.990680+00:00', 'updated_at': '2026-02-24T12:40:20.990683+00:00', 'score': None}\n",
      "{'namespace': ['1', 'memories'], 'key': '5d36c526-f165-457e-b56e-ba7cad876502', 'value': {'content': 'My name is Lance. I like to bike.'}, 'created_at': '2026-02-24T12:40:20.990777+00:00', 'updated_at': '2026-02-24T12:40:20.990778+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search \n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dce3d189-d996-43b8-a25e-5a2e127d8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5951cc13-98e2-41a1-a61f-a28af33e0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Lance.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Lance.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99125bf0-36ae-4ba8-81a9-669ad37b115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (chatcmpl-tool-aa53ff354432edc5)\n",
      " Call ID: chatcmpl-tool-aa53ff354432edc5\n",
      "  Args:\n",
      "    content: Lance mentioned having a nice bike ride in San Francisco this morning.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bd4b620-a80b-46bd-a328-3af54e68c2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Lance mentioned having a nice bike ride in San Francisco this morning.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf5a0600-f82b-49a0-8ffb-3b880d6a7028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Lance mentioned having a nice bike ride in San Francisco this morning.'})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4588cb1-011a-40a3-ab86-617372ddea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor.invoke({\"messages\": updated_conversation, \n",
    "                                     \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4b6fa55-607c-4986-8051-bb7f2a1742a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (chatcmpl-tool-81ed7ed2ed29931e)\n",
      " Call ID: chatcmpl-tool-81ed7ed2ed29931e\n",
      "  Args:\n",
      "    content: I was thinking about my Japan, and going back this winter! Lance mentioned having a nice bike ride in San Francisco this morning.\n",
      "  Memory (chatcmpl-tool-887c1cf0983f698a)\n",
      " Call ID: chatcmpl-tool-887c1cf0983f698a\n",
      "  Args:\n",
      "    content: I went to Tartine and ate a croissant.\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c63de1d1-06f7-428a-801c-343538d86a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I was thinking about my Japan, and going back this winter! Lance mentioned having a nice bike ride in San Francisco this morning.'\n",
      "content='I went to Tartine and ate a croissant.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3c2a270-c077-4185-a8f9-8162de325a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-tool-81ed7ed2ed29931e', 'json_doc_id': '0'}\n",
      "{'id': 'chatcmpl-tool-887c1cf0983f698a'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da597c-0191-4cf6-8718-9a1c9a989b2a",
   "metadata": {},
   "source": [
    "#### Chatbot with collection schema updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ee6368c-73ea-4076-962d-fdf65d99da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Memory schema\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    # This allows the extractor to insert new memories\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user. \n",
    "\n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "\n",
    "Current Memory (may include updated memories from this conversation): \n",
    "\n",
    "{memory}\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    # merge_message_runs returns a generator, not a list.\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": updated_messages, \n",
    "                                        \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5192c63-2a7d-4791-9040-ab486571166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi again, Lance! How's your day going so far?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58f638f1-c51c-4d9c-a21f-afc1d2af2dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a lot of fun! San Francisco has some great biking routes. Do you have a favorite trail or area you like to explore?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ca9977-f4d3-4e93-8059-82d21f1c29c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '1'], 'key': 'fb60cf2e-ec1b-4937-9663-312aa8ec1d6b', 'value': {'content': 'User likes to bike around San Francisco.'}, 'created_at': '2025-10-23T10:10:28.353800+00:00', 'updated_at': '2025-10-23T10:10:28.353800+00:00', 'score': None}\n",
      "{'namespace': ['memories', '1'], 'key': '5b580449-ec12-4de9-9f2c-bbb013ad1dec', 'value': {'content': 'User likes to bike around San Francisco.'}, 'created_at': '2025-10-23T10:10:28.353800+00:00', 'updated_at': '2025-10-23T10:10:28.353800+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e58de613-83cf-4532-8d15-b6b3a98f6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Biking and bakeries make a great combination! Do you have a favorite bakery in San Francisco, or are you still exploring different ones?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a8c1568-c51c-4105-82d7-f4a862adfa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Since you enjoy biking around San Francisco, you might like to visit some of these bakeries that are not only delicious but also offer a nice ride:\n",
      "\n",
      "1. **Tartine Bakery** - Located in the Mission District, it's a classic spot known for its bread and pastries. The area is bike-friendly, and you can enjoy a nice ride through the neighborhood.\n",
      "\n",
      "2. **Arsicault Bakery** - Situated in the Richmond District, it's famous for its croissants. The ride there can be quite scenic, especially if you take a route through Golden Gate Park.\n",
      "\n",
      "3. **B. Patisserie** - In Lower Pacific Heights, this bakery offers a variety of pastries and is known for its kouign-amann. The area is great for a leisurely bike ride.\n",
      "\n",
      "4. **Mr. Holmes Bakehouse** - Located in the Tenderloin, it's known for its cruffins. The ride there can be an adventure, and you can explore the nearby neighborhoods.\n",
      "\n",
      "5. **Craftsman and Wolves** - In the Mission District, this bakery offers unique pastries and a modern vibe. It's another great spot to visit while biking around the Mission.\n",
      "\n",
      "Do any of these sound like a good destination for your next ride?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819dc04-1977-47f1-b611-af729bbb360b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
